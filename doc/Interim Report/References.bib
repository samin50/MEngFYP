% Components
@misc{
    7inchdisplay,
    year = {n.d},
    author = {DFRobot},
    title = {7 Inch HDMI Display with USB TouchScreen},
    howpublished = {\url{https://www.farnell.com/datasheets/3162025.pdf}},
    note = {Accessed: 19-01-2024}
}

@misc{
    pi4,
    year = {n.d},
    author = {Raspberry Pi Foundation},
    title = {Raspberry Pi 4 Model B},
    howpublished = {\url{https://www.raspberrypi.com/products/raspberry-pi-4-model-b/}},
    note = {Accessed: 19-01-2024}
}

@misc{
    okdocamera,
    year = {n.d},
    author = {Okdo},
    title = {Okdo, Camera Module, CSI-2 with 2592 x 1944 Resolution},
    howpublished = {\url{https://uk.rs-online.com/web/p/raspberry-pi-cameras/2020456/}},
    note = {Accessed: 19-01-2024}
}

@misc{
    okdospec,
    year = {n.d},
    author = {Okdo},
    title = {Okdo, Camera Module, CSI-2 with 2592 x 1944 Resolution Specification},
    howpublished = {\url{https://docs.rs-online.com/b064/A700000006917308.pdf}},
    note = {Accessed: 19-01-2024}
}

@misc{
    xl4015,
    year = {n.d},
    author = {Katranji},
    title = {XL4015 Datasheet},
    howpublished = {\url{https://www.katranji.com/tocimages/files/457120-274359.pdf}},
    note = {Accessed: 22-01-2024}
}

@misc{
    rsproc14switch,
    year = {n.d},
    author = {RS Components},
    title = {RS PRO C14 Snap-In IEC Connector},
    howpublished = {\url{https://docs.rs-online.com/c6ad/0900766b815867b2.pdf}},
    note = {Accessed: 22-01-2024}
}

@misc{
    18awgwire,
    year = {n.d},
    author = {RS Components},
    title = {RS PRO 18 AWG Hook Up Wire, PVC Insulation},
    howpublished = {\url{https://docs.rs-online.com/770d/A700000007035534.pdf}},
    note = {Accessed: 22-01-2024}
}

@misc{
    irlz44n,
    year = {n.d},
    author = {Infineon},
    title = {IRLZ44N Datasheet},
    howpublished = {\url{https://www.infineon.com/dgdl/Infineon-IRLZ44N-DataSheet-v01_01-EN.pdf?fileId=5546d462533600a40153567217c32725}},
    note = {Accessed: 22-01-2024}
}
%  Software
@misc{
    freecad,
    year = {n.d},
    author = {FreeCAD},
    title = {FreeCAD},
    howpublished = {\url{https://www.freecadweb.org/}},
    note = {Accessed: 19-01-2024}
}

@misc{
    pylint,
    year = {n.d},
    author = {Pylint},
    title = {Pylint},
    howpublished = {\url{https://github.com/pylint-dev/pylint}},
    note = {Accessed: 19-01-2024}
}

@misc{
    python,
    year = {n.d},
    author = {Python},
    title = {Python},
    howpublished = {\url{https://www.python.org/}},
    note = {Accessed: 19-01-2024}
}

@misc{
    pygamedoc,
    year = {n.d},
    author = {Pygame},
    title = {Pygame Documentation},
    howpublished = {\url{https://www.pygame.org/docs/}},
    note = {Accessed: 22-01-2024}
}

@misc{
    tkinterdoc,
    year = {n.d},
    author = {Tkinter},
    title = {Tkinter Documentation},
    howpublished = {\url{https://docs.python.org/3/library/tkinter.html}},
    note = {Accessed: 22-01-2024}
}

@misc{
    pygamegui,
    year = {n.d},
    author = {MyreMylar},
    title = {Pygame GUI},
    howpublished = {\url{https://github.com/MyreMylar/pygame_gui/tree/0cbf7056518377b455d51a8d20167f4029756ad9}},
    note = {Accessed: 22-01-2024}
}

@misc{
    vscode,
    year = {n.d},
    author = {Visual Studio Code},
    title = {Visual Studio Code},
    howpublished = {\url{https://code.visualstudio.com/}},
    note = {Accessed: 22-01-2024}
}

@misc{
    git,
    year = {n.d},
    author = {Git},
    title = {Git},
    howpublished = {\url{https://git-scm.com/}},
    note = {Accessed: 22-01-2024}
}

@misc{
    github,
    year = {n.d},
    author = {GitHub},
    title = {GitHub},
    howpublished = {\url{https://github.com/}},
    note = {Accessed: 22-01-2024}
}

@misc{
    realvnc,
    year = {n.d},
    author = {RealVNC},
    title = {RealVNC},
    howpublished = {\url{https://www.realvnc.com/en/}},
    note = {Accessed: 22-01-2024}
}

@misc{
    fritzing,
    year = {n.d},
    author = {Fritzing},
    title = {Fritzing},
    howpublished = {\url{https://fritzing.org/}},
    note = {Accessed: 22-01-2024}
}

@misc{
    jupyter,
    year = {n.d},
    author = {Jupyter},
    title = {Jupyter},
    howpublished = {\url{https://jupyter.org/}},
    note = {Accessed: 25-01-2024}
}

@misc{
    customtkinter,
    year = {n.d},
    author = {Tom Schimansky},
    title = {Custom Tkinter Widgets},
    howpublished = {\url{https://github.com/TomSchimansky/CustomTkinter}},
    note = {Accessed: 25-01-2024}
}
% Research Papers
% Vibratory Bowl Feeder
@article{
    nam2019design,
    author = {Nam, Le and Mui, Nguyen and Tu, Dang},
    year = {2019},
    month = {02},
    pages = {102},
    title = {A method to design vibratory bowl feeder by using FEM modal analysis},
    volume = {57},
    journal = {Vietnam Journal of Science and Technology},
    doi = {10.15625/2525-2518/57/1/12859}
}

@article{
    REINHART2010191,
    title = {Design of a modular feeder for optimal operating performance},
    journal = {CIRP Journal of Manufacturing Science and Technology},
    volume = {3},
    number = {3},
    pages = {191-195},
    year = {2010},
    issn = {1755-5817},
    doi = {https://doi.org/10.1016/j.cirpj.2010.09.003},
    url = {https://www.sciencedirect.com/science/article/pii/S1755581710000908},
    author = {Gunther Reinhart and Michael Loy},
    keywords = {Assembly, Handling, Part feeding},
    abstract = {Flexible feeding technology is one of the main challenges in modern assembly systems. A promising approach is a new modular feeding system, which was developed at the iwb. This paper presents a method to ensure an optimal operating performance of the new feeder at single or double line frequency. Hereby, the modular system's natural frequencies are adjusted adequately during the development phase by adapting the masses and inertias of the relevant components. This is done with the aid of a structural mechanical model of the modular feeding system, which is derived and verified on a product-neutral basic set-up. Finally, the application of the model during the development phase of the modular feeder is presented.}
}

@article{
    ForceAnalysisofVibratoryBowlFeeder,
    author = {Silversides, Richard and Dai, Jian S and Seneviratne, Lakmal},
    title = "{Force Analysis of a Vibratory Bowl Feeder for Automatic Assembly}",
    journal = {Journal of Mechanical Design},
    volume = {127},
    number = {4},
    pages = {637-645},
    year = {2004},
    month = {08},
    abstract = "{This paper investigates the vibratory bowl feeder for automatic assembly, presents a geometric model of the feeder, and develops force analysis, leading to dynamical modeling of the vibratory feeder. Based on the leaf-spring modeling of the three legs of the symmetrically arranged bowl of the feeder, and equating the vibratory feeder to a three-legged parallel mechanism, the paper reveals the geometric property of the feeder. The effects of the leaf-spring legs are transformed to forces and moments acting on the base and bowl of the feeder. Resultant forces are obtained based upon the coordinate transformation, and the moment analysis is produced based upon the orthogonality of the orientation matrix. This reveals the characteristics of the feeder, that the resultant force is along the z-axis and the resultant moment is about the z direction and further generates the closed-form motion equation. The analysis presents a dynamic model that integrates the angular displacement of the bowl with the displacement of the leaf-spring legs. Both Newtonian and Lagrangian approaches are used to verify the model, and an industrial case-based simulation is used to demonstrate the results.}",
    issn = {1050-0472},
    doi = {10.1115/1.1897407},
    url = {https://doi.org/10.1115/1.1897407},
    eprint = {https://asmedigitalcollection.asme.org/mechanicaldesign/article-pdf/127/4/637/5806987/637\_1.pdf},
}

@book{
    zhang2019design,
  title={Design and Development of an Automated Sorting and Orienting Machine for Vials},
  author={Zhang, Z. and Massachusetts Institute of Technology. Department of Mechanical Engineering},
  url={https://books.google.co.uk/books?id=Mi5WzQEACAAJ},
  year={2019},
  publisher={Massachusetts Institute of Technology, Department of Mechanical Engineering}
}

% Conveyor Belt
@inproceedings{
    Dhenge2013MechanicalNS,
  booktitle={n.a},
  title={Mechanical Nut-Bolt Sorting using Principle Component Analysis and Artificial Neural Network},
  author={Amol I. Dhenge and Nāgpur and A. S. Khobragade},
  year={2013},
  url={https://api.semanticscholar.org/CorpusID:201742258}
}

@article{
    eggsorting,
author = {Quilloy, Erwin and Delfin, C. and Pepito, M.},
year = {2018},
month = {04},
pages = {918-926},
title = {Single-line automated sorter using mechatronics and machine vision system for Philippine table eggs},
volume = {13},
journal = {African Journal of Agricultural Research},
doi = {10.5897/AJAR2018.13113}
}

%  Existing Products
@article{Xu2020,
  author    = {Yuanyuan Xu and Genke Yang and Jiliang Luo and Jianan He and Chenxi Huang},
  title     = {An Electronic Component Recognition Algorithm Based on Deep Learning with a Faster SqueezeNet},
  journal   = {Mathematical Problems in Engineering},
  volume    = {2020},
  pages     = {2940286},
  year      = {2020},
  doi       = {10.1155/2020/2940286},
  url       = {https://doi.org/10.1155/2020/2940286},
  abstract  = {Electronic component recognition plays an important role in industrial production, electronic manufacturing, and testing. This paper selects multiple deep learning networks for testing and optimizes the SqueezeNet network. The Faster SqueezeNet network is proposed to reduce network parameter size and computational complexity without deteriorating network performance. The results show high performance in recognition accuracy, with ROC and AUC for capacitor and inductor reaching 1.0, and a reasoning time of about 2.67 ms, achieving industrial application level in terms of time consumption and performance.}
}

@Article{s22239079,
AUTHOR = {Chand, Praneel and Lal, Sunil},
TITLE = {Vision-Based Detection and Classification of Used Electronic Parts},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {23},
ARTICLE-NUMBER = {9079},
URL = {https://www.mdpi.com/1424-8220/22/23/9079},
PubMedID = {36501783},
ISSN = {1424-8220},
ABSTRACT = {Economic and environmental sustainability is becoming increasingly important in today&rsquo;s world. Electronic waste (e-waste) is on the rise and options to reuse parts should be explored. Hence, this paper presents the development of vision-based methods for the detection and classification of used electronics parts. In particular, the problem of classifying commonly used and relatively expensive electronic project parts such as capacitors, potentiometers, and voltage regulator ICs is investigated. A multiple object workspace scenario with an overhead camera is investigated. A customized object detection algorithm determines regions of interest and extracts data for classification. Three classification methods are explored: (a) shallow neural networks (SNNs), (b) support vector machines (SVMs), and (c) deep learning with convolutional neural networks (CNNs). All three methods utilize 30 &times; 30-pixel grayscale image inputs. Shallow neural networks achieved the lowest overall accuracy of 85.6%. The SVM implementation produced its best results using a cubic kernel and principal component analysis (PCA) with 20 features. An overall accuracy of 95.2% was achieved with this setting. The deep learning CNN model has three convolution layers, two pooling layers, one fully connected layer, softmax, and a classification layer. The convolution layer filter size was set to four and adjusting the number of filters produced little variation in accuracy. An overall accuracy of 98.1% was achieved with the CNN model.},
DOI = {10.3390/s22239079}
}

@article{Guo2021,
  author    = {Ce Guo and Xiao-ling Lv and Yan Zhang and Ming-lu Zhang},
  title     = {Improved YOLOv4-tiny network for real-time electronic component detection},
  journal   = {Scientific Reports},
  volume    = {11},
  number    = {1},
  pages     = {22744},
  year      = {2021},
  doi       = {10.1038/s41598-021-02225-y},
  url       = {https://doi.org/10.1038/s41598-021-02225-y},
  abstract  = {In the electronics industry environment, rapid recognition of objects to be grasped from digital images is essential for visual guidance of intelligent robots. This paper proposes an improved YOLOv4-tiny method for detecting electronic components. The method enhances the accuracy of the original algorithm and is validated on an electronic component dataset, showing significant improvements in detection accuracy. This development provides a technical reference for the advancement of manufacturing robots in the electronics industry.}
}

@INPROCEEDINGS{9166199,
  author={Sismananda, Pertiwang and Abdurohman, Maman and Putrada, Aji Gautama},
  booktitle={2020 8th International Conference on Information and Communication Technology (ICoICT)}, 
  title={Performance Comparison of Yolo-Lite and YoloV3 Using Raspberry Pi and MotionEyeOS}, 
  year={2020},
  volume={},
  number={},
  pages={1-7},
  keywords={Cameras;Object recognition;Software;Measurement;Prototypes;IP networks;Computer vision;Computer Vision;OpenCV;Raspberry Pi Camera;Yolo;YoloV3;Yolo-Lite},
  doi={10.1109/ICoICT49345.2020.9166199}}

@INPROCEEDINGS{8939034,
  author={Muminovic, Mia and Sokic, Emir},
  booktitle={2019 XXVII International Conference on Information, Communication and Automation Technologies (ICAT)}, 
  title={Automatic Segmentation and Classification of Resistors in Digital Images}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  keywords={Resistors;Image color analysis;Feature extraction;Image segmentation;Immune system;Shape;image processing;segmentation;identification;classification},
  doi={10.1109/ICAT47117.2019.8939034}
  }


  % YOLO
@misc{
  neuralmagic,
    year = {n.d},
  author = {Neural Magic},
  title = {YOLOv8 Detection 10x Faster With DeepSparse—Over 500 FPS on a CPU},
  howpublished = {\url{https://neuralmagic.com/blog/yolov8-detection-10x-faster-with-deepsparse-500-fps-on-a-cpu/}},
}

@misc{
    sparseml,
    year = {n.d},
    author = {Neural Magic},
    title = {SparseML},
    howpublished = {\url{https://github.com/neuralmagic/sparseml}}
}

@misc{
    deepsparse,
    year = {n.d},
    author = {Neural Magic},
    title = {DeepSparse},
    howpublished = {\url{https://github.com/neuralmagic/deepsparse}}
}

@article{yolo,
 author = {Terven, Juan and Cordova-Esparza, Diana-Margarita},
 journal = {n.j},
 year = {2023},
 month = {04},
 pages = {},
 title = {A Comprehensive Review of YOLO: From YOLOv1 to YOLOv8 and Beyond}
}

% Computer Vision
@article{Yang_2023,
   title={A Survey on Deep Semi-Supervised Learning},
   volume={35},
   ISSN={2326-3865},
   url={http://dx.doi.org/10.1109/TKDE.2022.3220219},
   DOI={10.1109/tkde.2022.3220219},
   number={9},
   journal={IEEE Transactions on Knowledge and Data Engineering},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Yang, Xiangli and Song, Zixing and King, Irwin and Xu, Zenglin},
   year={2023},
   month=sep, pages={8934–8954} }
